{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "85V6Wmb2OYmW",
    "outputId": "7df7cc23-bc05-4fc7-8771-a708cfaa6b5d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.17.5)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (3.10.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.1.8)\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (2.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu==2.1.0) (45.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.11.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.16.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.1.0) (2.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
      "Requirement already satisfied: typeguard in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons) (2.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.1.0\n",
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VW3mXzUXMyL_",
    "outputId": "71748536-5d14-47f3-8227-97674a510102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.1.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jd1BZwn_MyMS",
    "outputId": "4732d166-2ad0-4c2f-8300-3e685c0237ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/gdrive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "jupygk4662bI",
    "outputId": "4283090b-afca-4237-8e38-4e4530303a40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/images/faces/89_2.jpeg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/images/faces/23_1.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/images/faces/20_0.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/images/faces/61_0.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/images/faces/152_0.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             path  label\n",
       "0   ./data/images/faces/89_2.jpeg      1\n",
       "1   ./data/images/faces/23_1.jpeg      0\n",
       "2   ./data/images/faces/20_0.jpeg      0\n",
       "3   ./data/images/faces/61_0.jpeg      0\n",
       "4  ./data/images/faces/152_0.jpeg      0"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_path = \"/content/gdrive/My Drive/tinkoffCV\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(work_path, \"data/face_labels.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5COMgNK7BZO"
   },
   "outputs": [],
   "source": [
    "paths, labels = df.values[:, 0], np.array(df.values[:, 1], dtype=np.uint8)\n",
    "paths = np.array(list(map(lambda path: os.path.join(work_path, path[2:]), paths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IgAUfjRn7I8R"
   },
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05sd9j8w7Frk"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "def load_img(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    \n",
    "    return tf.image.resize_with_pad(img, 32, 32), label\n",
    "\n",
    "def augmentation(img, label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "def create_dataset(paths, labels, trainable=True, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    dataset = dataset.map(load_img, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    if trainable:\n",
    "        dataset = dataset.shuffle(len(paths))\n",
    "        dataset = dataset.map(augmentation, num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdInqT6w7Fub"
   },
   "outputs": [],
   "source": [
    "train_ds = create_dataset(paths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zVCZLMPI8Hqo"
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "sLvBl-SpMyNK",
    "outputId": "4da82e5c-6050-42ce-eade-113801d269c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 16)          4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 90,672\n",
      "Trainable params: 90,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(3, 3), strides=1, padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=None),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDCLGJyHMyNQ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=tfa.losses.TripletSemiHardLoss())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpKMzo1e8SNs"
   },
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UkEIGSGqMyNe",
    "outputId": "6865e1b5-4781-4a46-daab-34e3e763e4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 18 steps\n",
      "Epoch 1/1000\n",
      " 1/18 [>.............................] - ETA: 22:49 - loss: 0.9904WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.254830). Check your callbacks.\n",
      "11/18 [=================>............] - ETA: 51s - loss: 0.9819 \n",
      "Epoch 00001: loss improved from inf to 0.98250, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 81s 4s/step - loss: 0.9863\n",
      "Epoch 2/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.9666\n",
      "Epoch 00002: loss did not improve from 0.98250\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 1.0172\n",
      "Epoch 3/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.9474 \n",
      "Epoch 00003: loss improved from 0.98250 to 0.95321, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.9501\n",
      "Epoch 4/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.9377\n",
      "Epoch 00004: loss improved from 0.95321 to 0.93550, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.9338\n",
      "Epoch 5/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.8959\n",
      "Epoch 00005: loss did not improve from 0.93550\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.9658\n",
      "Epoch 6/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.8341\n",
      "Epoch 00006: loss improved from 0.93550 to 0.83781, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.8454\n",
      "Epoch 7/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.8532\n",
      "Epoch 00007: loss did not improve from 0.83781\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.8754\n",
      "Epoch 8/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.9363\n",
      "Epoch 00008: loss did not improve from 0.83781\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 1.0024\n",
      "Epoch 9/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.8811\n",
      "Epoch 00009: loss did not improve from 0.83781\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.9336\n",
      "Epoch 10/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.8020\n",
      "Epoch 00010: loss improved from 0.83781 to 0.79096, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.7921\n",
      "Epoch 11/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7884\n",
      "Epoch 00011: loss did not improve from 0.79096\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.8030\n",
      "Epoch 12/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7938\n",
      "Epoch 00012: loss did not improve from 0.79096\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.8184\n",
      "Epoch 13/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 0.9732\n",
      "Epoch 00013: loss did not improve from 0.79096\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.9740\n",
      "Epoch 14/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.8047\n",
      "Epoch 00014: loss did not improve from 0.79096\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.8103\n",
      "Epoch 15/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.8118\n",
      "Epoch 00015: loss did not improve from 0.79096\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.8373\n",
      "Epoch 16/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.9081\n",
      "Epoch 00016: loss did not improve from 0.79096\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.8701\n",
      "Epoch 17/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.7300\n",
      "Epoch 00017: loss improved from 0.79096 to 0.72142, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.7243\n",
      "Epoch 18/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6799\n",
      "Epoch 00018: loss did not improve from 0.72142\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.7439\n",
      "Epoch 19/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.7032\n",
      "Epoch 00019: loss did not improve from 0.72142\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.7612\n",
      "Epoch 20/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.7689 \n",
      "Epoch 00020: loss improved from 0.72142 to 0.70460, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.7043\n",
      "Epoch 21/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.6989\n",
      "Epoch 00021: loss did not improve from 0.70460\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.7222\n",
      "Epoch 22/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.7045\n",
      "Epoch 00022: loss did not improve from 0.70460\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.7909\n",
      "Epoch 23/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.7332\n",
      "Epoch 00023: loss did not improve from 0.70460\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.8334\n",
      "Epoch 24/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6624\n",
      "Epoch 00024: loss improved from 0.70460 to 0.65518, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6336\n",
      "Epoch 25/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6214\n",
      "Epoch 00025: loss did not improve from 0.65518\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6709\n",
      "Epoch 26/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.6298\n",
      "Epoch 00026: loss improved from 0.65518 to 0.63020, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.6308\n",
      "Epoch 27/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6836\n",
      "Epoch 00027: loss did not improve from 0.63020\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.6587\n",
      "Epoch 28/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6556\n",
      "Epoch 00028: loss did not improve from 0.63020\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.6657\n",
      "Epoch 29/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.6770\n",
      "Epoch 00029: loss did not improve from 0.63020\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6882\n",
      "Epoch 30/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5724\n",
      "Epoch 00030: loss improved from 0.63020 to 0.59281, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5942\n",
      "Epoch 31/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6217\n",
      "Epoch 00031: loss did not improve from 0.59281\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5911\n",
      "Epoch 32/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5506\n",
      "Epoch 00032: loss improved from 0.59281 to 0.58198, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.5871\n",
      "Epoch 33/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6557\n",
      "Epoch 00033: loss did not improve from 0.58198\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6756\n",
      "Epoch 34/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.5596\n",
      "Epoch 00034: loss improved from 0.58198 to 0.57818, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5788\n",
      "Epoch 35/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6421\n",
      "Epoch 00035: loss did not improve from 0.57818\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6146\n",
      "Epoch 36/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5631\n",
      "Epoch 00036: loss improved from 0.57818 to 0.55085, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.5420\n",
      "Epoch 37/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.7365\n",
      "Epoch 00037: loss did not improve from 0.55085\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.7222\n",
      "Epoch 38/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.5267\n",
      "Epoch 00038: loss improved from 0.55085 to 0.52595, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.5246\n",
      "Epoch 39/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6634\n",
      "Epoch 00039: loss did not improve from 0.52595\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6767\n",
      "Epoch 40/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.6869\n",
      "Epoch 00040: loss did not improve from 0.52595\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.6825\n",
      "Epoch 41/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6330\n",
      "Epoch 00041: loss did not improve from 0.52595\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.5890\n",
      "Epoch 42/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.6011\n",
      "Epoch 00042: loss did not improve from 0.52595\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.6314\n",
      "Epoch 43/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.5845\n",
      "Epoch 00043: loss did not improve from 0.52595\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.5950\n",
      "Epoch 44/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.4652\n",
      "Epoch 00044: loss improved from 0.52595 to 0.51053, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5483\n",
      "Epoch 45/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.5004\n",
      "Epoch 00045: loss did not improve from 0.51053\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.6088\n",
      "Epoch 46/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4917\n",
      "Epoch 00046: loss did not improve from 0.51053\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5367\n",
      "Epoch 47/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.6142\n",
      "Epoch 00047: loss did not improve from 0.51053\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.6286\n",
      "Epoch 48/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.4919\n",
      "Epoch 00048: loss did not improve from 0.51053\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.4955\n",
      "Epoch 49/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6134\n",
      "Epoch 00049: loss did not improve from 0.51053\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.6794\n",
      "Epoch 50/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5106\n",
      "Epoch 00050: loss did not improve from 0.51053\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.6064\n",
      "Epoch 51/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.5426\n",
      "Epoch 00051: loss did not improve from 0.51053\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.5109\n",
      "Epoch 52/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.4905\n",
      "Epoch 00052: loss improved from 0.51053 to 0.48488, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.4867\n",
      "Epoch 53/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.7007 \n",
      "Epoch 00053: loss did not improve from 0.48488\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6805\n",
      "Epoch 54/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.5612\n",
      "Epoch 00054: loss did not improve from 0.48488\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.5584\n",
      "Epoch 55/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4444\n",
      "Epoch 00055: loss improved from 0.48488 to 0.41996, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.4073\n",
      "Epoch 56/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.6230\n",
      "Epoch 00056: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.6411\n",
      "Epoch 57/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.6340\n",
      "Epoch 00057: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.6993\n",
      "Epoch 58/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5097\n",
      "Epoch 00058: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5131\n",
      "Epoch 59/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.5029\n",
      "Epoch 00059: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.4658\n",
      "Epoch 60/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5769\n",
      "Epoch 00060: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.5501\n",
      "Epoch 61/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.4480\n",
      "Epoch 00061: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4896\n",
      "Epoch 62/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5075\n",
      "Epoch 00062: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.5006\n",
      "Epoch 63/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4441\n",
      "Epoch 00063: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.4851\n",
      "Epoch 64/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5401\n",
      "Epoch 00064: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.5227\n",
      "Epoch 65/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4313\n",
      "Epoch 00065: loss did not improve from 0.41996\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.4606\n",
      "Epoch 66/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3940\n",
      "Epoch 00066: loss improved from 0.41996 to 0.41109, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.4204\n",
      "Epoch 67/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.4941\n",
      "Epoch 00067: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4744\n",
      "Epoch 68/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4466\n",
      "Epoch 00068: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4487\n",
      "Epoch 69/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.4814\n",
      "Epoch 00069: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5844\n",
      "Epoch 70/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5212\n",
      "Epoch 00070: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.6063\n",
      "Epoch 71/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.5175\n",
      "Epoch 00071: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.5514\n",
      "Epoch 72/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5035\n",
      "Epoch 00072: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.5110\n",
      "Epoch 73/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.5860\n",
      "Epoch 00073: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.6626\n",
      "Epoch 74/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4348\n",
      "Epoch 00074: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.4281\n",
      "Epoch 75/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4299\n",
      "Epoch 00075: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.5327\n",
      "Epoch 76/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.4394\n",
      "Epoch 00076: loss did not improve from 0.41109\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4417\n",
      "Epoch 77/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3675\n",
      "Epoch 00077: loss improved from 0.41109 to 0.38113, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 51ms/step - loss: 0.3857\n",
      "Epoch 78/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5196\n",
      "Epoch 00078: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.5130\n",
      "Epoch 79/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4410\n",
      "Epoch 00079: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4117\n",
      "Epoch 80/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4491\n",
      "Epoch 00080: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3967\n",
      "Epoch 81/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.4865 \n",
      "Epoch 00081: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.3760\n",
      "Epoch 82/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.5311\n",
      "Epoch 00082: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.4962\n",
      "Epoch 83/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.4875\n",
      "Epoch 00083: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4779\n",
      "Epoch 84/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3741\n",
      "Epoch 00084: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3858\n",
      "Epoch 85/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.4001\n",
      "Epoch 00085: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.4596\n",
      "Epoch 86/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.4005\n",
      "Epoch 00086: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.4048\n",
      "Epoch 87/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.5678\n",
      "Epoch 00087: loss did not improve from 0.38113\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.5634\n",
      "Epoch 88/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3575\n",
      "Epoch 00088: loss improved from 0.38113 to 0.36809, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3554\n",
      "Epoch 89/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.4308\n",
      "Epoch 00089: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.3950\n",
      "Epoch 90/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.4423\n",
      "Epoch 00090: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4260\n",
      "Epoch 91/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3865\n",
      "Epoch 00091: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5060\n",
      "Epoch 92/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.3856\n",
      "Epoch 00092: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4575\n",
      "Epoch 93/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.4545\n",
      "Epoch 00093: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4465\n",
      "Epoch 94/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4375\n",
      "Epoch 00094: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.5193\n",
      "Epoch 95/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4599\n",
      "Epoch 00095: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4758\n",
      "Epoch 96/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.4083\n",
      "Epoch 00096: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.4352\n",
      "Epoch 97/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4798\n",
      "Epoch 00097: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.5109\n",
      "Epoch 98/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.4828\n",
      "Epoch 00098: loss did not improve from 0.36809\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.4569\n",
      "Epoch 99/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3658\n",
      "Epoch 00099: loss improved from 0.36809 to 0.33533, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 56ms/step - loss: 0.3462\n",
      "Epoch 100/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3157\n",
      "Epoch 00100: loss did not improve from 0.33533\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.3338\n",
      "Epoch 101/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 0.3075\n",
      "Epoch 00101: loss did not improve from 0.33533\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3312\n",
      "Epoch 102/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3357\n",
      "Epoch 00102: loss did not improve from 0.33533\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3997\n",
      "Epoch 103/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4905\n",
      "Epoch 00103: loss did not improve from 0.33533\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.4374\n",
      "Epoch 104/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3065\n",
      "Epoch 00104: loss did not improve from 0.33533\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3336\n",
      "Epoch 105/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3792\n",
      "Epoch 00105: loss improved from 0.33533 to 0.31334, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.3060\n",
      "Epoch 106/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3496\n",
      "Epoch 00106: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.3668\n",
      "Epoch 107/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.3367\n",
      "Epoch 00107: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3839\n",
      "Epoch 108/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3887\n",
      "Epoch 00108: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.3938\n",
      "Epoch 109/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.3407\n",
      "Epoch 00109: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3563\n",
      "Epoch 110/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4546\n",
      "Epoch 00110: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.4479\n",
      "Epoch 111/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4626\n",
      "Epoch 00111: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.4411\n",
      "Epoch 112/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4000\n",
      "Epoch 00112: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3990\n",
      "Epoch 113/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.3779\n",
      "Epoch 00113: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3769\n",
      "Epoch 114/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.4416\n",
      "Epoch 00114: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.3880\n",
      "Epoch 115/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.3085\n",
      "Epoch 00115: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3873\n",
      "Epoch 116/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3734\n",
      "Epoch 00116: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.3478\n",
      "Epoch 117/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.4395\n",
      "Epoch 00117: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4562\n",
      "Epoch 118/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4254\n",
      "Epoch 00118: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.4070\n",
      "Epoch 119/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.3632\n",
      "Epoch 00119: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.3583\n",
      "Epoch 120/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3443\n",
      "Epoch 00120: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.3322\n",
      "Epoch 121/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3527\n",
      "Epoch 00121: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.4229\n",
      "Epoch 122/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3331\n",
      "Epoch 00122: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.3348\n",
      "Epoch 123/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3296\n",
      "Epoch 00123: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.3965\n",
      "Epoch 124/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.3731\n",
      "Epoch 00124: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.4322\n",
      "Epoch 125/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3364\n",
      "Epoch 00125: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.3253\n",
      "Epoch 126/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3878\n",
      "Epoch 00126: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.4116\n",
      "Epoch 127/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3052\n",
      "Epoch 00127: loss did not improve from 0.31334\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3301\n",
      "Epoch 128/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2689\n",
      "Epoch 00128: loss improved from 0.31334 to 0.29204, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.3059\n",
      "Epoch 129/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3648\n",
      "Epoch 00129: loss did not improve from 0.29204\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.4020\n",
      "Epoch 130/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3581\n",
      "Epoch 00130: loss did not improve from 0.29204\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.3743\n",
      "Epoch 131/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.4187\n",
      "Epoch 00131: loss did not improve from 0.29204\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.3891\n",
      "Epoch 132/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2954\n",
      "Epoch 00132: loss did not improve from 0.29204\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3049\n",
      "Epoch 133/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2939\n",
      "Epoch 00133: loss improved from 0.29204 to 0.29133, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.3269\n",
      "Epoch 134/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2667\n",
      "Epoch 00134: loss improved from 0.29133 to 0.26633, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2656\n",
      "Epoch 135/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3383\n",
      "Epoch 00135: loss did not improve from 0.26633\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.3204\n",
      "Epoch 136/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3059\n",
      "Epoch 00136: loss did not improve from 0.26633\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3043\n",
      "Epoch 137/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2406\n",
      "Epoch 00137: loss improved from 0.26633 to 0.23078, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2228\n",
      "Epoch 138/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3191\n",
      "Epoch 00138: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3175\n",
      "Epoch 139/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3360\n",
      "Epoch 00139: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2881\n",
      "Epoch 140/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3105\n",
      "Epoch 00140: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.3285\n",
      "Epoch 141/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3554\n",
      "Epoch 00141: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.4423\n",
      "Epoch 142/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2949\n",
      "Epoch 00142: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2945\n",
      "Epoch 143/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2872\n",
      "Epoch 00143: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3111\n",
      "Epoch 144/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3164\n",
      "Epoch 00144: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2937\n",
      "Epoch 145/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3097\n",
      "Epoch 00145: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.3685\n",
      "Epoch 146/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.3378\n",
      "Epoch 00146: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3343\n",
      "Epoch 147/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2939\n",
      "Epoch 00147: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2792\n",
      "Epoch 148/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2221\n",
      "Epoch 00148: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.3478\n",
      "Epoch 149/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.3199\n",
      "Epoch 00149: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.3205\n",
      "Epoch 150/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.2377\n",
      "Epoch 00150: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2537\n",
      "Epoch 151/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2490\n",
      "Epoch 00151: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2394\n",
      "Epoch 152/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.3730\n",
      "Epoch 00152: loss did not improve from 0.23078\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.3532\n",
      "Epoch 153/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1945\n",
      "Epoch 00153: loss improved from 0.23078 to 0.19805, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.1912\n",
      "Epoch 154/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2514\n",
      "Epoch 00154: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2311\n",
      "Epoch 155/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3543\n",
      "Epoch 00155: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.3577\n",
      "Epoch 156/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1761\n",
      "Epoch 00156: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.3220\n",
      "Epoch 157/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1641\n",
      "Epoch 00157: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2742\n",
      "Epoch 158/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2623\n",
      "Epoch 00158: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2665\n",
      "Epoch 159/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1323\n",
      "Epoch 00159: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2229\n",
      "Epoch 160/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3743\n",
      "Epoch 00160: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.3747\n",
      "Epoch 161/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3052\n",
      "Epoch 00161: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3601\n",
      "Epoch 162/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3445\n",
      "Epoch 00162: loss did not improve from 0.19805\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.3007\n",
      "Epoch 163/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1837\n",
      "Epoch 00163: loss improved from 0.19805 to 0.18467, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1833\n",
      "Epoch 164/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2138\n",
      "Epoch 00164: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2155\n",
      "Epoch 165/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2508\n",
      "Epoch 00165: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2345\n",
      "Epoch 166/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2126\n",
      "Epoch 00166: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2322\n",
      "Epoch 167/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.2316\n",
      "Epoch 00167: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2263\n",
      "Epoch 168/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2486\n",
      "Epoch 00168: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3396\n",
      "Epoch 169/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2327\n",
      "Epoch 00169: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2361\n",
      "Epoch 170/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.3925\n",
      "Epoch 00170: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.3899\n",
      "Epoch 171/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1909\n",
      "Epoch 00171: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1807\n",
      "Epoch 172/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3490\n",
      "Epoch 00172: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2994\n",
      "Epoch 173/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2587\n",
      "Epoch 00173: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2655\n",
      "Epoch 174/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2571\n",
      "Epoch 00174: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2927\n",
      "Epoch 175/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3314\n",
      "Epoch 00175: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.3126\n",
      "Epoch 176/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2571\n",
      "Epoch 00176: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2734\n",
      "Epoch 177/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1982\n",
      "Epoch 00177: loss did not improve from 0.18467\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2053\n",
      "Epoch 178/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1649\n",
      "Epoch 00178: loss improved from 0.18467 to 0.16956, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 53ms/step - loss: 0.1637\n",
      "Epoch 179/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2149\n",
      "Epoch 00179: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2117\n",
      "Epoch 180/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.2089\n",
      "Epoch 00180: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2084\n",
      "Epoch 181/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2110\n",
      "Epoch 00181: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1882\n",
      "Epoch 182/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3132\n",
      "Epoch 00182: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.3516\n",
      "Epoch 183/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1488\n",
      "Epoch 00183: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.1818\n",
      "Epoch 184/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1640\n",
      "Epoch 00184: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1904\n",
      "Epoch 185/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2637\n",
      "Epoch 00185: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2353\n",
      "Epoch 186/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2106\n",
      "Epoch 00186: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1922\n",
      "Epoch 187/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.2059\n",
      "Epoch 00187: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1947\n",
      "Epoch 188/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2234\n",
      "Epoch 00188: loss did not improve from 0.16956\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2387\n",
      "Epoch 189/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1463\n",
      "Epoch 00189: loss improved from 0.16956 to 0.16063, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1732\n",
      "Epoch 190/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3312\n",
      "Epoch 00190: loss did not improve from 0.16063\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2641\n",
      "Epoch 191/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2323\n",
      "Epoch 00191: loss did not improve from 0.16063\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2224\n",
      "Epoch 192/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2106\n",
      "Epoch 00192: loss did not improve from 0.16063\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1880\n",
      "Epoch 193/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2283\n",
      "Epoch 00193: loss did not improve from 0.16063\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2149\n",
      "Epoch 194/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2149\n",
      "Epoch 00194: loss did not improve from 0.16063\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2152\n",
      "Epoch 195/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2747\n",
      "Epoch 00195: loss did not improve from 0.16063\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2781\n",
      "Epoch 196/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2330\n",
      "Epoch 00196: loss did not improve from 0.16063\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2839\n",
      "Epoch 197/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1505\n",
      "Epoch 00197: loss improved from 0.16063 to 0.14748, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1424\n",
      "Epoch 198/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2054\n",
      "Epoch 00198: loss did not improve from 0.14748\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1843\n",
      "Epoch 199/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.3681\n",
      "Epoch 00199: loss did not improve from 0.14748\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2884\n",
      "Epoch 200/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2288\n",
      "Epoch 00200: loss did not improve from 0.14748\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2941\n",
      "Epoch 201/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1539\n",
      "Epoch 00201: loss improved from 0.14748 to 0.13954, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1408\n",
      "Epoch 202/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1863\n",
      "Epoch 00202: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1669\n",
      "Epoch 203/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1556\n",
      "Epoch 00203: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1486\n",
      "Epoch 204/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1271\n",
      "Epoch 00204: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2104\n",
      "Epoch 205/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1819\n",
      "Epoch 00205: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2776\n",
      "Epoch 206/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.4270\n",
      "Epoch 00206: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.4364\n",
      "Epoch 207/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2735\n",
      "Epoch 00207: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.3514\n",
      "Epoch 208/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1670\n",
      "Epoch 00208: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1581\n",
      "Epoch 209/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1918\n",
      "Epoch 00209: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1830\n",
      "Epoch 210/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2374\n",
      "Epoch 00210: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2377\n",
      "Epoch 211/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3129\n",
      "Epoch 00211: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2787\n",
      "Epoch 212/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2286\n",
      "Epoch 00212: loss did not improve from 0.13954\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2230\n",
      "Epoch 213/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0847\n",
      "Epoch 00213: loss improved from 0.13954 to 0.10920, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 52ms/step - loss: 0.1508\n",
      "Epoch 214/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2058\n",
      "Epoch 00214: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2768\n",
      "Epoch 215/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2593\n",
      "Epoch 00215: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2481\n",
      "Epoch 216/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2505\n",
      "Epoch 00216: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2598\n",
      "Epoch 217/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2005\n",
      "Epoch 00217: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1712\n",
      "Epoch 218/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2385\n",
      "Epoch 00218: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2293\n",
      "Epoch 219/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1982\n",
      "Epoch 00219: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1842\n",
      "Epoch 220/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1441\n",
      "Epoch 00220: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.1696\n",
      "Epoch 221/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2730\n",
      "Epoch 00221: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3097\n",
      "Epoch 222/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3049\n",
      "Epoch 00222: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.2773\n",
      "Epoch 223/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3326\n",
      "Epoch 00223: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.3110\n",
      "Epoch 224/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1902\n",
      "Epoch 00224: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1592\n",
      "Epoch 225/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1353\n",
      "Epoch 00225: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1986\n",
      "Epoch 226/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1811\n",
      "Epoch 00226: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1738\n",
      "Epoch 227/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2034\n",
      "Epoch 00227: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.1873\n",
      "Epoch 228/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2981\n",
      "Epoch 00228: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.3587\n",
      "Epoch 229/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.3007\n",
      "Epoch 00229: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2845\n",
      "Epoch 230/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1584\n",
      "Epoch 00230: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1706\n",
      "Epoch 231/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1211\n",
      "Epoch 00231: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1117\n",
      "Epoch 232/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1482\n",
      "Epoch 00232: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1509\n",
      "Epoch 233/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.3391\n",
      "Epoch 00233: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2937\n",
      "Epoch 234/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1494\n",
      "Epoch 00234: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2229\n",
      "Epoch 235/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2299\n",
      "Epoch 00235: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2322\n",
      "Epoch 236/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2102\n",
      "Epoch 00236: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2766\n",
      "Epoch 237/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1778\n",
      "Epoch 00237: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1595\n",
      "Epoch 238/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1872\n",
      "Epoch 00238: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2558\n",
      "Epoch 239/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1548\n",
      "Epoch 00239: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1473\n",
      "Epoch 240/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2673\n",
      "Epoch 00240: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2743\n",
      "Epoch 241/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.3279\n",
      "Epoch 00241: loss did not improve from 0.10920\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.2238\n",
      "Epoch 242/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1158\n",
      "Epoch 00242: loss improved from 0.10920 to 0.10214, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.1051\n",
      "Epoch 243/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2385\n",
      "Epoch 00243: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2086\n",
      "Epoch 244/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1669\n",
      "Epoch 00244: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1680\n",
      "Epoch 245/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1443\n",
      "Epoch 00245: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2400\n",
      "Epoch 246/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1978\n",
      "Epoch 00246: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2178\n",
      "Epoch 247/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2289\n",
      "Epoch 00247: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2041\n",
      "Epoch 248/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1744\n",
      "Epoch 00248: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2493\n",
      "Epoch 249/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1067\n",
      "Epoch 00249: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1743\n",
      "Epoch 250/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1754\n",
      "Epoch 00250: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1737\n",
      "Epoch 251/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1862\n",
      "Epoch 00251: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2043\n",
      "Epoch 252/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1578\n",
      "Epoch 00252: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1493\n",
      "Epoch 253/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1098\n",
      "Epoch 00253: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1060\n",
      "Epoch 254/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1719\n",
      "Epoch 00254: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1513\n",
      "Epoch 255/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1434\n",
      "Epoch 00255: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1599\n",
      "Epoch 256/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1576\n",
      "Epoch 00256: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2401\n",
      "Epoch 257/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1114\n",
      "Epoch 00257: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1190\n",
      "Epoch 258/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1571\n",
      "Epoch 00258: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1791\n",
      "Epoch 259/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1582\n",
      "Epoch 00259: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2202\n",
      "Epoch 260/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1081\n",
      "Epoch 00260: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1102\n",
      "Epoch 261/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1109\n",
      "Epoch 00261: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1637\n",
      "Epoch 262/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1374\n",
      "Epoch 00262: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1276\n",
      "Epoch 263/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2441\n",
      "Epoch 00263: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.3074\n",
      "Epoch 264/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2045\n",
      "Epoch 00264: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2808\n",
      "Epoch 265/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1574\n",
      "Epoch 00265: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2686\n",
      "Epoch 266/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2130\n",
      "Epoch 00266: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.2283\n",
      "Epoch 267/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1989\n",
      "Epoch 00267: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1812\n",
      "Epoch 268/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1874\n",
      "Epoch 00268: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2547\n",
      "Epoch 269/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1498\n",
      "Epoch 00269: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1603\n",
      "Epoch 270/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1332\n",
      "Epoch 00270: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1318\n",
      "Epoch 271/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1007\n",
      "Epoch 00271: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1109\n",
      "Epoch 272/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2403\n",
      "Epoch 00272: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2470\n",
      "Epoch 273/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1696\n",
      "Epoch 00273: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2363\n",
      "Epoch 274/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2013\n",
      "Epoch 00274: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2118\n",
      "Epoch 275/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1903\n",
      "Epoch 00275: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1800\n",
      "Epoch 276/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1292\n",
      "Epoch 00276: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.1222\n",
      "Epoch 277/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0979\n",
      "Epoch 00277: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1272\n",
      "Epoch 278/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1447\n",
      "Epoch 00278: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2028\n",
      "Epoch 279/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1548\n",
      "Epoch 00279: loss did not improve from 0.10214\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1466\n",
      "Epoch 280/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0899\n",
      "Epoch 00280: loss improved from 0.10214 to 0.09582, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.1048\n",
      "Epoch 281/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1081\n",
      "Epoch 00281: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1702\n",
      "Epoch 282/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.2181\n",
      "Epoch 00282: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1945\n",
      "Epoch 283/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1444\n",
      "Epoch 00283: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1364\n",
      "Epoch 284/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1402\n",
      "Epoch 00284: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1207\n",
      "Epoch 285/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1973\n",
      "Epoch 00285: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1780\n",
      "Epoch 286/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1370\n",
      "Epoch 00286: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1196\n",
      "Epoch 287/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.2033 \n",
      "Epoch 00287: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1662\n",
      "Epoch 288/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1597\n",
      "Epoch 00288: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1302\n",
      "Epoch 289/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1328\n",
      "Epoch 00289: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1280\n",
      "Epoch 290/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.1497\n",
      "Epoch 00290: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1355\n",
      "Epoch 291/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1333\n",
      "Epoch 00291: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1262\n",
      "Epoch 292/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1921\n",
      "Epoch 00292: loss did not improve from 0.09582\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1721\n",
      "Epoch 293/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0791\n",
      "Epoch 00293: loss improved from 0.09582 to 0.08468, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.0818\n",
      "Epoch 294/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0514\n",
      "Epoch 00294: loss improved from 0.08468 to 0.07158, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0838\n",
      "Epoch 295/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0974\n",
      "Epoch 00295: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0802\n",
      "Epoch 296/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1456\n",
      "Epoch 00296: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1508\n",
      "Epoch 297/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1551\n",
      "Epoch 00297: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1939\n",
      "Epoch 298/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1593\n",
      "Epoch 00298: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1521\n",
      "Epoch 299/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1661\n",
      "Epoch 00299: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2550\n",
      "Epoch 300/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1500\n",
      "Epoch 00300: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1636\n",
      "Epoch 301/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1317\n",
      "Epoch 00301: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2038\n",
      "Epoch 302/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1418\n",
      "Epoch 00302: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1399\n",
      "Epoch 303/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0745\n",
      "Epoch 00303: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0717\n",
      "Epoch 304/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1240\n",
      "Epoch 00304: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2160\n",
      "Epoch 305/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.2471\n",
      "Epoch 00305: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.3594\n",
      "Epoch 306/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1662\n",
      "Epoch 00306: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2052\n",
      "Epoch 307/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1405\n",
      "Epoch 00307: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1330\n",
      "Epoch 308/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1519\n",
      "Epoch 00308: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1550\n",
      "Epoch 309/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.3444\n",
      "Epoch 00309: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.3437\n",
      "Epoch 310/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2084\n",
      "Epoch 00310: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2399\n",
      "Epoch 311/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.2555\n",
      "Epoch 00311: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2169\n",
      "Epoch 312/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0903\n",
      "Epoch 00312: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1040\n",
      "Epoch 313/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1506\n",
      "Epoch 00313: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2554\n",
      "Epoch 314/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0594\n",
      "Epoch 00314: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1504\n",
      "Epoch 315/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1244\n",
      "Epoch 00315: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1901\n",
      "Epoch 316/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1931\n",
      "Epoch 00316: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2169\n",
      "Epoch 317/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0954\n",
      "Epoch 00317: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0919\n",
      "Epoch 318/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1994\n",
      "Epoch 00318: loss did not improve from 0.07158\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2575\n",
      "Epoch 319/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0531\n",
      "Epoch 00319: loss improved from 0.07158 to 0.06945, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 55ms/step - loss: 0.0743\n",
      "Epoch 320/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1416\n",
      "Epoch 00320: loss did not improve from 0.06945\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1251\n",
      "Epoch 321/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1052\n",
      "Epoch 00321: loss did not improve from 0.06945\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0876\n",
      "Epoch 322/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1234\n",
      "Epoch 00322: loss did not improve from 0.06945\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0971\n",
      "Epoch 323/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0517\n",
      "Epoch 00323: loss improved from 0.06945 to 0.05728, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0633\n",
      "Epoch 324/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1270\n",
      "Epoch 00324: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2008\n",
      "Epoch 325/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0889\n",
      "Epoch 00325: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1206\n",
      "Epoch 326/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0978 \n",
      "Epoch 00326: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.1248\n",
      "Epoch 327/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0892\n",
      "Epoch 00327: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0868\n",
      "Epoch 328/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0999\n",
      "Epoch 00328: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1629\n",
      "Epoch 329/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1676\n",
      "Epoch 00329: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1586\n",
      "Epoch 330/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2302\n",
      "Epoch 00330: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2588\n",
      "Epoch 331/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1631\n",
      "Epoch 00331: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2239\n",
      "Epoch 332/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0985\n",
      "Epoch 00332: loss did not improve from 0.05728\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0877\n",
      "Epoch 333/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0463\n",
      "Epoch 00333: loss improved from 0.05728 to 0.05229, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0505\n",
      "Epoch 334/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0791\n",
      "Epoch 00334: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1131\n",
      "Epoch 335/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1108\n",
      "Epoch 00335: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0991\n",
      "Epoch 336/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1686\n",
      "Epoch 00336: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1612\n",
      "Epoch 337/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0884\n",
      "Epoch 00337: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1504\n",
      "Epoch 338/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0500\n",
      "Epoch 00338: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1327\n",
      "Epoch 339/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0628\n",
      "Epoch 00339: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0851\n",
      "Epoch 340/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1788\n",
      "Epoch 00340: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1692\n",
      "Epoch 341/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.2087\n",
      "Epoch 00341: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2662\n",
      "Epoch 342/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1248\n",
      "Epoch 00342: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2178\n",
      "Epoch 343/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1170\n",
      "Epoch 00343: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1098\n",
      "Epoch 344/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0917\n",
      "Epoch 00344: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0868\n",
      "Epoch 345/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0678\n",
      "Epoch 00345: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0687\n",
      "Epoch 346/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1548\n",
      "Epoch 00346: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2053\n",
      "Epoch 347/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0586\n",
      "Epoch 00347: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1505\n",
      "Epoch 348/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.1047\n",
      "Epoch 00348: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.1056\n",
      "Epoch 349/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1324\n",
      "Epoch 00349: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1253\n",
      "Epoch 350/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0626\n",
      "Epoch 00350: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0571\n",
      "Epoch 351/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1116\n",
      "Epoch 00351: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1003\n",
      "Epoch 352/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1441\n",
      "Epoch 00352: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1963\n",
      "Epoch 353/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1116\n",
      "Epoch 00353: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.1996\n",
      "Epoch 354/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0675\n",
      "Epoch 00354: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0617\n",
      "Epoch 355/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1231\n",
      "Epoch 00355: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.1824\n",
      "Epoch 356/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0414\n",
      "Epoch 00356: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0756\n",
      "Epoch 357/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1274\n",
      "Epoch 00357: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1860\n",
      "Epoch 358/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0752\n",
      "Epoch 00358: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0716\n",
      "Epoch 359/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0654\n",
      "Epoch 00359: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1363\n",
      "Epoch 360/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0801\n",
      "Epoch 00360: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1377\n",
      "Epoch 361/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1326\n",
      "Epoch 00361: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2080\n",
      "Epoch 362/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1656\n",
      "Epoch 00362: loss did not improve from 0.05229\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1568\n",
      "Epoch 363/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0381\n",
      "Epoch 00363: loss improved from 0.05229 to 0.05015, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.0484\n",
      "Epoch 364/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1086\n",
      "Epoch 00364: loss did not improve from 0.05015\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0995\n",
      "Epoch 365/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0355\n",
      "Epoch 00365: loss did not improve from 0.05015\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0520\n",
      "Epoch 366/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0241\n",
      "Epoch 00366: loss improved from 0.05015 to 0.02783, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0269\n",
      "Epoch 367/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0976\n",
      "Epoch 00367: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1664\n",
      "Epoch 368/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1315\n",
      "Epoch 00368: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1373\n",
      "Epoch 369/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0678\n",
      "Epoch 00369: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0627\n",
      "Epoch 370/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0665\n",
      "Epoch 00370: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0798\n",
      "Epoch 371/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1734\n",
      "Epoch 00371: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1586\n",
      "Epoch 372/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1092\n",
      "Epoch 00372: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1786\n",
      "Epoch 373/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1293\n",
      "Epoch 00373: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1277\n",
      "Epoch 374/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1395\n",
      "Epoch 00374: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1273\n",
      "Epoch 375/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1231\n",
      "Epoch 00375: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1506\n",
      "Epoch 376/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2600\n",
      "Epoch 00376: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2337\n",
      "Epoch 377/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0906\n",
      "Epoch 00377: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.1590\n",
      "Epoch 378/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0902\n",
      "Epoch 00378: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0771\n",
      "Epoch 379/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1713 \n",
      "Epoch 00379: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1555\n",
      "Epoch 380/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1264\n",
      "Epoch 00380: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1168\n",
      "Epoch 381/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1473\n",
      "Epoch 00381: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2343\n",
      "Epoch 382/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0754 \n",
      "Epoch 00382: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1633\n",
      "Epoch 383/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1205\n",
      "Epoch 00383: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1129\n",
      "Epoch 384/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2158\n",
      "Epoch 00384: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1924\n",
      "Epoch 385/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1223\n",
      "Epoch 00385: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1903\n",
      "Epoch 386/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1849\n",
      "Epoch 00386: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1749\n",
      "Epoch 387/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.1782\n",
      "Epoch 00387: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1675\n",
      "Epoch 388/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0881\n",
      "Epoch 00388: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.1349\n",
      "Epoch 389/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1106    \n",
      "Epoch 00389: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0722\n",
      "Epoch 390/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1499\n",
      "Epoch 00390: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1381\n",
      "Epoch 391/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1208\n",
      "Epoch 00391: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1513\n",
      "Epoch 392/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1568\n",
      "Epoch 00392: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.1255\n",
      "Epoch 393/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1231\n",
      "Epoch 00393: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1057\n",
      "Epoch 394/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0914\n",
      "Epoch 00394: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0810\n",
      "Epoch 395/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1021\n",
      "Epoch 00395: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1136\n",
      "Epoch 396/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0974\n",
      "Epoch 00396: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0869\n",
      "Epoch 397/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2176\n",
      "Epoch 00397: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2008\n",
      "Epoch 398/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1308\n",
      "Epoch 00398: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1218\n",
      "Epoch 399/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0724\n",
      "Epoch 00399: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1368\n",
      "Epoch 400/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1132\n",
      "Epoch 00400: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1071\n",
      "Epoch 401/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0388\n",
      "Epoch 00401: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0305\n",
      "Epoch 402/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1166\n",
      "Epoch 00402: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1104\n",
      "Epoch 403/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1137\n",
      "Epoch 00403: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1055\n",
      "Epoch 404/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0257\n",
      "Epoch 00404: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0354\n",
      "Epoch 405/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1294 \n",
      "Epoch 00405: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1172\n",
      "Epoch 406/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1619\n",
      "Epoch 00406: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2137\n",
      "Epoch 407/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1851\n",
      "Epoch 00407: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1796\n",
      "Epoch 408/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1657\n",
      "Epoch 00408: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1641\n",
      "Epoch 409/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1574\n",
      "Epoch 00409: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.1816\n",
      "Epoch 410/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0729\n",
      "Epoch 00410: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0648\n",
      "Epoch 411/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0617\n",
      "Epoch 00411: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0584\n",
      "Epoch 412/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0743\n",
      "Epoch 00412: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1045\n",
      "Epoch 413/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0516\n",
      "Epoch 00413: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1202\n",
      "Epoch 414/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0754\n",
      "Epoch 00414: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0714\n",
      "Epoch 415/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0458\n",
      "Epoch 00415: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0998\n",
      "Epoch 416/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0791\n",
      "Epoch 00416: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1437\n",
      "Epoch 417/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0620\n",
      "Epoch 00417: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0745\n",
      "Epoch 418/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1871\n",
      "Epoch 00418: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1742\n",
      "Epoch 419/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0821\n",
      "Epoch 00419: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0777\n",
      "Epoch 420/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0692\n",
      "Epoch 00420: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0812\n",
      "Epoch 421/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0631\n",
      "Epoch 00421: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0518\n",
      "Epoch 422/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0642\n",
      "Epoch 00422: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0607\n",
      "Epoch 423/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0454\n",
      "Epoch 00423: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0519\n",
      "Epoch 424/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0696\n",
      "Epoch 00424: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1493\n",
      "Epoch 425/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0547\n",
      "Epoch 00425: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0518\n",
      "Epoch 426/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1145    \n",
      "Epoch 00426: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1112\n",
      "Epoch 427/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0749\n",
      "Epoch 00427: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0662\n",
      "Epoch 428/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0231\n",
      "Epoch 00428: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0957\n",
      "Epoch 429/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0804\n",
      "Epoch 00429: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1538\n",
      "Epoch 430/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1440\n",
      "Epoch 00430: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.2062\n",
      "Epoch 431/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0911\n",
      "Epoch 00431: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.0802\n",
      "Epoch 432/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0686\n",
      "Epoch 00432: loss did not improve from 0.02783\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0811\n",
      "Epoch 433/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0134\n",
      "Epoch 00433: loss improved from 0.02783 to 0.01238, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0120\n",
      "Epoch 434/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0704\n",
      "Epoch 00434: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1675\n",
      "Epoch 435/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0714\n",
      "Epoch 00435: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0638\n",
      "Epoch 436/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0906\n",
      "Epoch 00436: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0861\n",
      "Epoch 437/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0388\n",
      "Epoch 00437: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0441\n",
      "Epoch 438/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0814\n",
      "Epoch 00438: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0981\n",
      "Epoch 439/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1753\n",
      "Epoch 00439: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1322\n",
      "Epoch 440/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0389\n",
      "Epoch 00440: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0368\n",
      "Epoch 441/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0970\n",
      "Epoch 00441: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1311\n",
      "Epoch 442/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1309\n",
      "Epoch 00442: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1093\n",
      "Epoch 443/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1253\n",
      "Epoch 00443: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1189\n",
      "Epoch 444/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1502\n",
      "Epoch 00444: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1421\n",
      "Epoch 445/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0620\n",
      "Epoch 00445: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0795\n",
      "Epoch 446/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0547\n",
      "Epoch 00446: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0543\n",
      "Epoch 447/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0855\n",
      "Epoch 00447: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0856\n",
      "Epoch 448/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.1946\n",
      "Epoch 00448: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1514\n",
      "Epoch 449/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0104    \n",
      "Epoch 00449: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0235\n",
      "Epoch 450/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0836\n",
      "Epoch 00450: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0709\n",
      "Epoch 451/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0328\n",
      "Epoch 00451: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1204\n",
      "Epoch 452/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0159\n",
      "Epoch 00452: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0435\n",
      "Epoch 453/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0862\n",
      "Epoch 00453: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0781\n",
      "Epoch 454/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1683\n",
      "Epoch 00454: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2121\n",
      "Epoch 455/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1261\n",
      "Epoch 00455: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1194\n",
      "Epoch 456/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1362\n",
      "Epoch 00456: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2008\n",
      "Epoch 457/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0287\n",
      "Epoch 00457: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0275\n",
      "Epoch 458/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0276\n",
      "Epoch 00458: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0261\n",
      "Epoch 459/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0251\n",
      "Epoch 00459: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0247\n",
      "Epoch 460/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1131\n",
      "Epoch 00460: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1547\n",
      "Epoch 461/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0779\n",
      "Epoch 00461: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1332\n",
      "Epoch 462/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0655\n",
      "Epoch 00462: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0620\n",
      "Epoch 463/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0580\n",
      "Epoch 00463: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0861\n",
      "Epoch 464/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0848\n",
      "Epoch 00464: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0759\n",
      "Epoch 465/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1342\n",
      "Epoch 00465: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1270\n",
      "Epoch 466/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0741\n",
      "Epoch 00466: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0684\n",
      "Epoch 467/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0955\n",
      "Epoch 00467: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0904\n",
      "Epoch 468/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0763\n",
      "Epoch 00468: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0746\n",
      "Epoch 469/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0857\n",
      "Epoch 00469: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1393\n",
      "Epoch 470/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.2434\n",
      "Epoch 00470: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.2457\n",
      "Epoch 471/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0882\n",
      "Epoch 00471: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0954\n",
      "Epoch 472/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0914\n",
      "Epoch 00472: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1139\n",
      "Epoch 473/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0496\n",
      "Epoch 00473: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0787\n",
      "Epoch 474/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1878\n",
      "Epoch 00474: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1508\n",
      "Epoch 475/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0695\n",
      "Epoch 00475: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.0815\n",
      "Epoch 476/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0969\n",
      "Epoch 00476: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0916\n",
      "Epoch 477/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0438\n",
      "Epoch 00477: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0461\n",
      "Epoch 478/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1064\n",
      "Epoch 00478: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0888\n",
      "Epoch 479/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0608\n",
      "Epoch 00479: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0786\n",
      "Epoch 480/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1070\n",
      "Epoch 00480: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0866\n",
      "Epoch 481/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1030\n",
      "Epoch 00481: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1543\n",
      "Epoch 482/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0234\n",
      "Epoch 00482: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1076\n",
      "Epoch 483/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1906\n",
      "Epoch 00483: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2480\n",
      "Epoch 484/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0225\n",
      "Epoch 00484: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0213\n",
      "Epoch 485/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0882\n",
      "Epoch 00485: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0743\n",
      "Epoch 486/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0840\n",
      "Epoch 00486: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0685\n",
      "Epoch 487/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0851\n",
      "Epoch 00487: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0835\n",
      "Epoch 488/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0591\n",
      "Epoch 00488: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0560\n",
      "Epoch 489/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0745\n",
      "Epoch 00489: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0916\n",
      "Epoch 490/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1073\n",
      "Epoch 00490: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1016\n",
      "Epoch 491/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0792\n",
      "Epoch 00491: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1277\n",
      "Epoch 492/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0707\n",
      "Epoch 00492: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.1427\n",
      "Epoch 493/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1270\n",
      "Epoch 00493: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1216\n",
      "Epoch 494/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0936\n",
      "Epoch 00494: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0974\n",
      "Epoch 495/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1232\n",
      "Epoch 00495: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1136\n",
      "Epoch 496/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0772\n",
      "Epoch 00496: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0685\n",
      "Epoch 497/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2471\n",
      "Epoch 00497: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2029\n",
      "Epoch 498/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2048\n",
      "Epoch 00498: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1904\n",
      "Epoch 499/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1181\n",
      "Epoch 00499: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.1117\n",
      "Epoch 500/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0684\n",
      "Epoch 00500: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0589\n",
      "Epoch 501/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0508\n",
      "Epoch 00501: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1117\n",
      "Epoch 502/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1056\n",
      "Epoch 00502: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.1247\n",
      "Epoch 503/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0382\n",
      "Epoch 00503: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0362\n",
      "Epoch 504/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0634\n",
      "Epoch 00504: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0631\n",
      "Epoch 505/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0347\n",
      "Epoch 00505: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0293\n",
      "Epoch 506/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1424\n",
      "Epoch 00506: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1201\n",
      "Epoch 507/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0328\n",
      "Epoch 00507: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0977\n",
      "Epoch 508/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0807\n",
      "Epoch 00508: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1198\n",
      "Epoch 509/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0656\n",
      "Epoch 00509: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0720\n",
      "Epoch 510/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0799\n",
      "Epoch 00510: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0808\n",
      "Epoch 511/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0426\n",
      "Epoch 00511: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0420\n",
      "Epoch 512/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0545\n",
      "Epoch 00512: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1126\n",
      "Epoch 513/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0377\n",
      "Epoch 00513: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0794\n",
      "Epoch 514/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1818\n",
      "Epoch 00514: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.1471\n",
      "Epoch 515/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1818\n",
      "Epoch 00515: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1570\n",
      "Epoch 516/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0534\n",
      "Epoch 00516: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0411\n",
      "Epoch 517/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0598\n",
      "Epoch 00517: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1366\n",
      "Epoch 518/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0404\n",
      "Epoch 00518: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0362\n",
      "Epoch 519/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0492\n",
      "Epoch 00519: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0585\n",
      "Epoch 520/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1660 \n",
      "Epoch 00520: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1915\n",
      "Epoch 521/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1284\n",
      "Epoch 00521: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1150\n",
      "Epoch 522/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1685\n",
      "Epoch 00522: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1557\n",
      "Epoch 523/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1078\n",
      "Epoch 00523: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1135\n",
      "Epoch 524/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0818\n",
      "Epoch 00524: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0774\n",
      "Epoch 525/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0655\n",
      "Epoch 00525: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0571\n",
      "Epoch 526/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0499\n",
      "Epoch 00526: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0498\n",
      "Epoch 527/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1571\n",
      "Epoch 00527: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1581\n",
      "Epoch 528/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0447\n",
      "Epoch 00528: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1087\n",
      "Epoch 529/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1328\n",
      "Epoch 00529: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1195\n",
      "Epoch 530/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1273\n",
      "Epoch 00530: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1083\n",
      "Epoch 531/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0715\n",
      "Epoch 00531: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0677\n",
      "Epoch 532/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0982\n",
      "Epoch 00532: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0820\n",
      "Epoch 533/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0300\n",
      "Epoch 00533: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0285\n",
      "Epoch 534/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0715    \n",
      "Epoch 00534: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0517\n",
      "Epoch 535/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0808\n",
      "Epoch 00535: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0846\n",
      "Epoch 536/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0655\n",
      "Epoch 00536: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0853\n",
      "Epoch 537/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0442\n",
      "Epoch 00537: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0540\n",
      "Epoch 538/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0187     \n",
      "Epoch 00538: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0165\n",
      "Epoch 539/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1159\n",
      "Epoch 00539: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1097\n",
      "Epoch 540/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0468\n",
      "Epoch 00540: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0443\n",
      "Epoch 541/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0704\n",
      "Epoch 00541: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0854\n",
      "Epoch 542/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1202\n",
      "Epoch 00542: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1228\n",
      "Epoch 543/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1602\n",
      "Epoch 00543: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.1516\n",
      "Epoch 544/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0364\n",
      "Epoch 00544: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0324\n",
      "Epoch 545/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0599\n",
      "Epoch 00545: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1258\n",
      "Epoch 546/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1692\n",
      "Epoch 00546: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1170\n",
      "Epoch 547/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0512\n",
      "Epoch 00547: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0519\n",
      "Epoch 548/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1272\n",
      "Epoch 00548: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1827\n",
      "Epoch 549/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1497\n",
      "Epoch 00549: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1334\n",
      "Epoch 550/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1449\n",
      "Epoch 00550: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2178\n",
      "Epoch 551/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0215\n",
      "Epoch 00551: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0473\n",
      "Epoch 552/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0433\n",
      "Epoch 00552: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0446\n",
      "Epoch 553/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0360\n",
      "Epoch 00553: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0470\n",
      "Epoch 554/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0637\n",
      "Epoch 00554: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0543\n",
      "Epoch 555/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0721\n",
      "Epoch 00555: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0682\n",
      "Epoch 556/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0528\n",
      "Epoch 00556: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1215\n",
      "Epoch 557/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0852\n",
      "Epoch 00557: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0894\n",
      "Epoch 558/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0689\n",
      "Epoch 00558: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0571\n",
      "Epoch 559/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1700\n",
      "Epoch 00559: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2191\n",
      "Epoch 560/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0606\n",
      "Epoch 00560: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0529\n",
      "Epoch 561/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0824\n",
      "Epoch 00561: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0771\n",
      "Epoch 562/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0460\n",
      "Epoch 00562: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1239\n",
      "Epoch 563/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0832\n",
      "Epoch 00563: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1322\n",
      "Epoch 564/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0483\n",
      "Epoch 00564: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0430\n",
      "Epoch 565/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0897\n",
      "Epoch 00565: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0658\n",
      "Epoch 566/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0974     \n",
      "Epoch 00566: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0612\n",
      "Epoch 567/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0655\n",
      "Epoch 00567: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0620\n",
      "Epoch 568/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0809 \n",
      "Epoch 00568: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0468\n",
      "Epoch 569/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0568\n",
      "Epoch 00569: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0485\n",
      "Epoch 570/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0586\n",
      "Epoch 00570: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0559\n",
      "Epoch 571/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0624\n",
      "Epoch 00571: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0706\n",
      "Epoch 572/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0823\n",
      "Epoch 00572: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0666\n",
      "Epoch 573/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1419\n",
      "Epoch 00573: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1358\n",
      "Epoch 574/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0223\n",
      "Epoch 00574: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0517\n",
      "Epoch 575/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1619\n",
      "Epoch 00575: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.1197\n",
      "Epoch 576/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0334\n",
      "Epoch 00576: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0301\n",
      "Epoch 577/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00577: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0921\n",
      "Epoch 578/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0560\n",
      "Epoch 00578: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1119\n",
      "Epoch 579/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0562\n",
      "Epoch 00579: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0506\n",
      "Epoch 580/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0347\n",
      "Epoch 00580: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0329\n",
      "Epoch 581/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1592\n",
      "Epoch 00581: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1506\n",
      "Epoch 582/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1211\n",
      "Epoch 00582: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1018\n",
      "Epoch 583/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0544\n",
      "Epoch 00583: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0484\n",
      "Epoch 584/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0786\n",
      "Epoch 00584: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0708\n",
      "Epoch 585/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0554\n",
      "Epoch 00585: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0539\n",
      "Epoch 586/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0878\n",
      "Epoch 00586: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0782\n",
      "Epoch 587/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0614\n",
      "Epoch 00587: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0477\n",
      "Epoch 588/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1175\n",
      "Epoch 00588: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0973\n",
      "Epoch 589/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0537\n",
      "Epoch 00589: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0508\n",
      "Epoch 590/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0277\n",
      "Epoch 00590: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0384\n",
      "Epoch 591/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0712\n",
      "Epoch 00591: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0655\n",
      "Epoch 592/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0338\n",
      "Epoch 00592: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0334\n",
      "Epoch 593/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0470\n",
      "Epoch 00593: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0493\n",
      "Epoch 594/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0461\n",
      "Epoch 00594: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0413\n",
      "Epoch 595/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1499\n",
      "Epoch 00595: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2051\n",
      "Epoch 596/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0549\n",
      "Epoch 00596: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0495\n",
      "Epoch 597/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0923\n",
      "Epoch 00597: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.1393\n",
      "Epoch 598/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0186\n",
      "Epoch 00598: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.0199\n",
      "Epoch 599/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1074\n",
      "Epoch 00599: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2017\n",
      "Epoch 600/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0858\n",
      "Epoch 00600: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1592\n",
      "Epoch 601/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1582\n",
      "Epoch 00601: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.2292\n",
      "Epoch 602/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1354\n",
      "Epoch 00602: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1273\n",
      "Epoch 603/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0533\n",
      "Epoch 00603: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0465\n",
      "Epoch 604/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1435\n",
      "Epoch 00604: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1640\n",
      "Epoch 605/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0233\n",
      "Epoch 00605: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1113\n",
      "Epoch 606/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0175\n",
      "Epoch 00606: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0165\n",
      "Epoch 607/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0459\n",
      "Epoch 00607: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0482\n",
      "Epoch 608/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1860\n",
      "Epoch 00608: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.2190\n",
      "Epoch 609/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1532\n",
      "Epoch 00609: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1848\n",
      "Epoch 610/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0495\n",
      "Epoch 00610: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0509\n",
      "Epoch 611/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0553\n",
      "Epoch 00611: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0528\n",
      "Epoch 612/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0789\n",
      "Epoch 00612: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0746\n",
      "Epoch 613/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0621\n",
      "Epoch 00613: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0530\n",
      "Epoch 614/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0303\n",
      "Epoch 00614: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0318\n",
      "Epoch 615/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0545\n",
      "Epoch 00615: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0492\n",
      "Epoch 616/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0540\n",
      "Epoch 00616: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1151\n",
      "Epoch 617/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1459\n",
      "Epoch 00617: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1595\n",
      "Epoch 618/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0841\n",
      "Epoch 00618: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0750\n",
      "Epoch 619/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0304\n",
      "Epoch 00619: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0346\n",
      "Epoch 620/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0718\n",
      "Epoch 00620: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1582\n",
      "Epoch 621/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0255\n",
      "Epoch 00621: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0851\n",
      "Epoch 622/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0530\n",
      "Epoch 00622: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1294\n",
      "Epoch 623/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0124\n",
      "Epoch 00623: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1310\n",
      "Epoch 624/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1201\n",
      "Epoch 00624: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1101\n",
      "Epoch 625/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0642\n",
      "Epoch 00625: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0531\n",
      "Epoch 626/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1028\n",
      "Epoch 00626: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0973\n",
      "Epoch 627/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0515\n",
      "Epoch 00627: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1079\n",
      "Epoch 628/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0819\n",
      "Epoch 00628: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1445\n",
      "Epoch 629/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1343\n",
      "Epoch 00629: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0980\n",
      "Epoch 630/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0552\n",
      "Epoch 00630: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0584\n",
      "Epoch 631/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0361\n",
      "Epoch 00631: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1115\n",
      "Epoch 632/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0551\n",
      "Epoch 00632: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0577\n",
      "Epoch 633/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 0.0515\n",
      "Epoch 00633: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0546\n",
      "Epoch 634/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0388\n",
      "Epoch 00634: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1134\n",
      "Epoch 635/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1760\n",
      "Epoch 00635: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1897\n",
      "Epoch 636/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0788\n",
      "Epoch 00636: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0904\n",
      "Epoch 637/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1851\n",
      "Epoch 00637: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.1595\n",
      "Epoch 638/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0522\n",
      "Epoch 00638: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0494\n",
      "Epoch 639/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0421\n",
      "Epoch 00639: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0411\n",
      "Epoch 640/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0244\n",
      "Epoch 00640: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0225\n",
      "Epoch 641/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0350\n",
      "Epoch 00641: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0335\n",
      "Epoch 642/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0447\n",
      "Epoch 00642: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0965\n",
      "Epoch 643/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0408\n",
      "Epoch 00643: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0940\n",
      "Epoch 644/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0269\n",
      "Epoch 00644: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0408\n",
      "Epoch 645/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0953\n",
      "Epoch 00645: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0880\n",
      "Epoch 646/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1007\n",
      "Epoch 00646: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1000\n",
      "Epoch 647/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1269\n",
      "Epoch 00647: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1006\n",
      "Epoch 648/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1029\n",
      "Epoch 00648: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0866\n",
      "Epoch 649/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0354\n",
      "Epoch 00649: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0583\n",
      "Epoch 650/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0175    \n",
      "Epoch 00650: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0557\n",
      "Epoch 651/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1328\n",
      "Epoch 00651: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1890\n",
      "Epoch 652/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0669\n",
      "Epoch 00652: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0633\n",
      "Epoch 653/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0573\n",
      "Epoch 00653: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0510\n",
      "Epoch 654/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1372\n",
      "Epoch 00654: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1298\n",
      "Epoch 655/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0971\n",
      "Epoch 00655: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1389\n",
      "Epoch 656/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0880\n",
      "Epoch 00656: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0923\n",
      "Epoch 657/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0763\n",
      "Epoch 00657: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1275\n",
      "Epoch 658/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00658: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0171\n",
      "Epoch 659/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0601\n",
      "Epoch 00659: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0535\n",
      "Epoch 660/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0341    \n",
      "Epoch 00660: loss did not improve from 0.01238\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0306\n",
      "Epoch 661/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0136\n",
      "Epoch 00661: loss improved from 0.01238 to 0.01174, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 54ms/step - loss: 0.0113\n",
      "Epoch 662/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0664\n",
      "Epoch 00662: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0871\n",
      "Epoch 663/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1036\n",
      "Epoch 00663: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0981\n",
      "Epoch 664/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0192\n",
      "Epoch 00664: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0171\n",
      "Epoch 665/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1058\n",
      "Epoch 00665: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0839\n",
      "Epoch 666/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0253\n",
      "Epoch 00666: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0294\n",
      "Epoch 667/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0269\n",
      "Epoch 00667: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0255\n",
      "Epoch 668/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0050\n",
      "Epoch 00668: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0677\n",
      "Epoch 669/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0913\n",
      "Epoch 00669: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1495\n",
      "Epoch 670/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0377    \n",
      "Epoch 00670: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0288\n",
      "Epoch 671/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0369\n",
      "Epoch 00671: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0416\n",
      "Epoch 672/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0527\n",
      "Epoch 00672: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0472\n",
      "Epoch 673/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1092\n",
      "Epoch 00673: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1034\n",
      "Epoch 674/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1420\n",
      "Epoch 00674: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1264\n",
      "Epoch 675/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1580\n",
      "Epoch 00675: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1319\n",
      "Epoch 676/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0553\n",
      "Epoch 00676: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0524\n",
      "Epoch 677/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1001\n",
      "Epoch 00677: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1034\n",
      "Epoch 678/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1539\n",
      "Epoch 00678: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1197\n",
      "Epoch 679/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1220     \n",
      "Epoch 00679: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1699\n",
      "Epoch 680/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0711\n",
      "Epoch 00680: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.0569\n",
      "Epoch 681/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0519\n",
      "Epoch 00681: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1254\n",
      "Epoch 682/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0197\n",
      "Epoch 00682: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0778\n",
      "Epoch 683/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0755\n",
      "Epoch 00683: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0715\n",
      "Epoch 684/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0536\n",
      "Epoch 00684: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1107\n",
      "Epoch 685/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0385\n",
      "Epoch 00685: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0976\n",
      "Epoch 686/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1022\n",
      "Epoch 00686: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0982\n",
      "Epoch 687/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0488\n",
      "Epoch 00687: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1075\n",
      "Epoch 688/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0323\n",
      "Epoch 00688: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1176\n",
      "Epoch 689/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1089\n",
      "Epoch 00689: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0999\n",
      "Epoch 690/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1651\n",
      "Epoch 00690: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.2531\n",
      "Epoch 691/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0401 \n",
      "Epoch 00691: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0488\n",
      "Epoch 692/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1430\n",
      "Epoch 00692: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1309\n",
      "Epoch 693/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0891\n",
      "Epoch 00693: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0843\n",
      "Epoch 694/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0659\n",
      "Epoch 00694: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0606\n",
      "Epoch 695/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1252\n",
      "Epoch 00695: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1890\n",
      "Epoch 696/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0891\n",
      "Epoch 00696: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0763\n",
      "Epoch 697/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1238\n",
      "Epoch 00697: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1764\n",
      "Epoch 698/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0640\n",
      "Epoch 00698: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0581\n",
      "Epoch 699/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0116\n",
      "Epoch 00699: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0134\n",
      "Epoch 700/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1001\n",
      "Epoch 00700: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1565\n",
      "Epoch 701/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0728\n",
      "Epoch 00701: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1250\n",
      "Epoch 702/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0202\n",
      "Epoch 00702: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0192\n",
      "Epoch 703/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0108\n",
      "Epoch 00703: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0189\n",
      "Epoch 704/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0309\n",
      "Epoch 00704: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0338\n",
      "Epoch 705/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1319\n",
      "Epoch 00705: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1825\n",
      "Epoch 706/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0544\n",
      "Epoch 00706: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0475\n",
      "Epoch 707/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0401\n",
      "Epoch 00707: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0396\n",
      "Epoch 708/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00708: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0155\n",
      "Epoch 709/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0154\n",
      "Epoch 00709: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0846\n",
      "Epoch 710/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1750\n",
      "Epoch 00710: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1461\n",
      "Epoch 711/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0703\n",
      "Epoch 00711: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0634\n",
      "Epoch 712/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0528\n",
      "Epoch 00712: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0512\n",
      "Epoch 713/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0821\n",
      "Epoch 00713: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0776\n",
      "Epoch 714/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1212\n",
      "Epoch 00714: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1133\n",
      "Epoch 715/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0562\n",
      "Epoch 00715: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0532\n",
      "Epoch 716/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0586\n",
      "Epoch 00716: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1141\n",
      "Epoch 717/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1042\n",
      "Epoch 00717: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1512\n",
      "Epoch 718/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0097\n",
      "Epoch 00718: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0781\n",
      "Epoch 719/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0601\n",
      "Epoch 00719: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0811\n",
      "Epoch 720/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0061\n",
      "Epoch 00720: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.0161\n",
      "Epoch 721/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0320\n",
      "Epoch 00721: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0303\n",
      "Epoch 722/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0275\n",
      "Epoch 00722: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0246\n",
      "Epoch 723/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0201\n",
      "Epoch 00723: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0259\n",
      "Epoch 724/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0169\n",
      "Epoch 00724: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0161\n",
      "Epoch 725/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0357\n",
      "Epoch 00725: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0277\n",
      "Epoch 726/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0997\n",
      "Epoch 00726: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0888\n",
      "Epoch 727/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0642\n",
      "Epoch 00727: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0469\n",
      "Epoch 728/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0593\n",
      "Epoch 00728: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0572\n",
      "Epoch 729/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0232\n",
      "Epoch 00729: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0207\n",
      "Epoch 730/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0687\n",
      "Epoch 00730: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0601\n",
      "Epoch 731/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0750\n",
      "Epoch 00731: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0619\n",
      "Epoch 732/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0288\n",
      "Epoch 00732: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0525\n",
      "Epoch 733/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0114\n",
      "Epoch 00733: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0723\n",
      "Epoch 734/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1080\n",
      "Epoch 00734: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0905\n",
      "Epoch 735/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0185\n",
      "Epoch 00735: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0361\n",
      "Epoch 736/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0474\n",
      "Epoch 00736: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0422\n",
      "Epoch 737/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0262\n",
      "Epoch 00737: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0233\n",
      "Epoch 738/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1049\n",
      "Epoch 00738: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0993\n",
      "Epoch 739/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0416\n",
      "Epoch 00739: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0394\n",
      "Epoch 740/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0170\n",
      "Epoch 00740: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0162\n",
      "Epoch 741/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0687\n",
      "Epoch 00741: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0639\n",
      "Epoch 742/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0799\n",
      "Epoch 00742: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0752\n",
      "Epoch 743/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1017\n",
      "Epoch 00743: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1810\n",
      "Epoch 744/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0739\n",
      "Epoch 00744: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0699\n",
      "Epoch 745/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0973\n",
      "Epoch 00745: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0921\n",
      "Epoch 746/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0287\n",
      "Epoch 00746: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0242\n",
      "Epoch 747/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0185\n",
      "Epoch 00747: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0175\n",
      "Epoch 748/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0287    \n",
      "Epoch 00748: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0479\n",
      "Epoch 749/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0323\n",
      "Epoch 00749: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0929\n",
      "Epoch 750/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0156\n",
      "Epoch 00750: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0160\n",
      "Epoch 751/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0444\n",
      "Epoch 00751: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0658\n",
      "Epoch 752/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0734\n",
      "Epoch 00752: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0694\n",
      "Epoch 753/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0319\n",
      "Epoch 00753: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0638\n",
      "Epoch 754/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0300\n",
      "Epoch 00754: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0935\n",
      "Epoch 755/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1725     \n",
      "Epoch 00755: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1664\n",
      "Epoch 756/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0708\n",
      "Epoch 00756: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0605\n",
      "Epoch 757/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0405\n",
      "Epoch 00757: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0431\n",
      "Epoch 758/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0613\n",
      "Epoch 00758: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0476\n",
      "Epoch 759/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0225\n",
      "Epoch 00759: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0877\n",
      "Epoch 760/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0293\n",
      "Epoch 00760: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0254\n",
      "Epoch 761/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1755\n",
      "Epoch 00761: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1327\n",
      "Epoch 762/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00762: loss did not improve from 0.01174\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0133\n",
      "Epoch 763/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0115\n",
      "Epoch 00763: loss improved from 0.01174 to 0.01126, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 61ms/step - loss: 0.0109\n",
      "Epoch 764/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1195\n",
      "Epoch 00764: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1065\n",
      "Epoch 765/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0589\n",
      "Epoch 00765: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1365\n",
      "Epoch 766/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0783\n",
      "Epoch 00766: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0916\n",
      "Epoch 767/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0783\n",
      "Epoch 00767: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0741\n",
      "Epoch 768/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0915\n",
      "Epoch 00768: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1189\n",
      "Epoch 769/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0925\n",
      "Epoch 00769: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0827\n",
      "Epoch 770/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0173\n",
      "Epoch 00770: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0187\n",
      "Epoch 771/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0329\n",
      "Epoch 00771: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0929\n",
      "Epoch 772/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0146\n",
      "Epoch 00772: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0138\n",
      "Epoch 773/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0305\n",
      "Epoch 00773: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1140\n",
      "Epoch 774/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0594\n",
      "Epoch 00774: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0557\n",
      "Epoch 775/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0209\n",
      "Epoch 00775: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0180\n",
      "Epoch 776/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0216\n",
      "Epoch 00776: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0207\n",
      "Epoch 777/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0406\n",
      "Epoch 00777: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0364\n",
      "Epoch 778/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0362\n",
      "Epoch 00778: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0744\n",
      "Epoch 779/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0279\n",
      "Epoch 00779: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0507\n",
      "Epoch 780/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0513\n",
      "Epoch 00780: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0735\n",
      "Epoch 781/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1015\n",
      "Epoch 00781: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0961\n",
      "Epoch 782/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1507\n",
      "Epoch 00782: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1426\n",
      "Epoch 783/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0615\n",
      "Epoch 00783: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1152\n",
      "Epoch 784/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0361\n",
      "Epoch 00784: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0975\n",
      "Epoch 785/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0599\n",
      "Epoch 00785: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1218\n",
      "Epoch 786/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0428\n",
      "Epoch 00786: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1626\n",
      "Epoch 787/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0160\n",
      "Epoch 00787: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0434\n",
      "Epoch 788/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0285\n",
      "Epoch 00788: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0269\n",
      "Epoch 789/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0632\n",
      "Epoch 00789: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0668\n",
      "Epoch 790/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1033\n",
      "Epoch 00790: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0917\n",
      "Epoch 791/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0478\n",
      "Epoch 00791: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0402\n",
      "Epoch 792/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0162\n",
      "Epoch 00792: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0781\n",
      "Epoch 793/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0365\n",
      "Epoch 00793: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0320\n",
      "Epoch 794/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0312\n",
      "Epoch 00794: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0945\n",
      "Epoch 795/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0375\n",
      "Epoch 00795: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0473\n",
      "Epoch 796/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0860\n",
      "Epoch 00796: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0822\n",
      "Epoch 797/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0400\n",
      "Epoch 00797: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0379\n",
      "Epoch 798/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0187     \n",
      "Epoch 00798: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0163\n",
      "Epoch 799/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0389\n",
      "Epoch 00799: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0316\n",
      "Epoch 800/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00800: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0309\n",
      "Epoch 801/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.1190\n",
      "Epoch 00801: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0894\n",
      "Epoch 802/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0325\n",
      "Epoch 00802: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0290\n",
      "Epoch 803/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0770\n",
      "Epoch 00803: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0791\n",
      "Epoch 804/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1152\n",
      "Epoch 00804: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0918\n",
      "Epoch 805/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1901\n",
      "Epoch 00805: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1712\n",
      "Epoch 806/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0665\n",
      "Epoch 00806: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0580\n",
      "Epoch 807/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0419\n",
      "Epoch 00807: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.0320\n",
      "Epoch 808/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0413\n",
      "Epoch 00808: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0338\n",
      "Epoch 809/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0495\n",
      "Epoch 00809: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0469\n",
      "Epoch 810/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0439\n",
      "Epoch 00810: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0532\n",
      "Epoch 811/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0533\n",
      "Epoch 00811: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0516\n",
      "Epoch 812/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1524\n",
      "Epoch 00812: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1679\n",
      "Epoch 813/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1684\n",
      "Epoch 00813: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1640\n",
      "Epoch 814/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0761\n",
      "Epoch 00814: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0721\n",
      "Epoch 815/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0189\n",
      "Epoch 00815: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0188\n",
      "Epoch 816/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0262\n",
      "Epoch 00816: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0206\n",
      "Epoch 817/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0851\n",
      "Epoch 00817: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0670\n",
      "Epoch 818/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0184    \n",
      "Epoch 00818: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0265\n",
      "Epoch 819/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0215\n",
      "Epoch 00819: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0278\n",
      "Epoch 820/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0138\n",
      "Epoch 00820: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0193\n",
      "Epoch 821/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0260\n",
      "Epoch 00821: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0246\n",
      "Epoch 822/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0780\n",
      "Epoch 00822: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1372\n",
      "Epoch 823/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0072\n",
      "Epoch 00823: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.0707\n",
      "Epoch 824/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0651\n",
      "Epoch 00824: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0692\n",
      "Epoch 825/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1401\n",
      "Epoch 00825: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.1058\n",
      "Epoch 826/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0352\n",
      "Epoch 00826: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0282\n",
      "Epoch 827/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0496\n",
      "Epoch 00827: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0444\n",
      "Epoch 828/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1352\n",
      "Epoch 00828: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1834\n",
      "Epoch 829/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1587\n",
      "Epoch 00829: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.2140\n",
      "Epoch 830/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1422\n",
      "Epoch 00830: loss did not improve from 0.01126\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1845\n",
      "Epoch 831/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0084\n",
      "Epoch 00831: loss improved from 0.01126 to 0.00933, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.0125\n",
      "Epoch 832/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0704\n",
      "Epoch 00832: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0667\n",
      "Epoch 833/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1998\n",
      "Epoch 00833: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1871\n",
      "Epoch 834/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2888\n",
      "Epoch 00834: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.2538\n",
      "Epoch 835/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0332\n",
      "Epoch 00835: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0267\n",
      "Epoch 836/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0288\n",
      "Epoch 00836: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0892\n",
      "Epoch 837/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0566\n",
      "Epoch 00837: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0454\n",
      "Epoch 838/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0548\n",
      "Epoch 00838: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0449\n",
      "Epoch 839/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0160\n",
      "Epoch 00839: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0125\n",
      "Epoch 840/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0446\n",
      "Epoch 00840: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0373\n",
      "Epoch 841/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0149\n",
      "Epoch 00841: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0330\n",
      "Epoch 842/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.2298\n",
      "Epoch 00842: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1705\n",
      "Epoch 843/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0073    \n",
      "Epoch 00843: loss did not improve from 0.00933\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1587\n",
      "Epoch 844/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0049\n",
      "Epoch 00844: loss improved from 0.00933 to 0.00651, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 62ms/step - loss: 0.0074\n",
      "Epoch 845/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0371\n",
      "Epoch 00845: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0311\n",
      "Epoch 846/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0278\n",
      "Epoch 00846: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0263\n",
      "Epoch 847/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0155\n",
      "Epoch 00847: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0384\n",
      "Epoch 848/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0082\n",
      "Epoch 00848: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0077\n",
      "Epoch 849/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0936    \n",
      "Epoch 00849: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0990\n",
      "Epoch 850/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0381\n",
      "Epoch 00850: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0923\n",
      "Epoch 851/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0167\n",
      "Epoch 00851: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0171\n",
      "Epoch 852/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0111\n",
      "Epoch 00852: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0794\n",
      "Epoch 853/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0145\n",
      "Epoch 00853: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0779\n",
      "Epoch 854/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1278\n",
      "Epoch 00854: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.1931\n",
      "Epoch 855/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0231\n",
      "Epoch 00855: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0206\n",
      "Epoch 856/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0542\n",
      "Epoch 00856: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0562\n",
      "Epoch 857/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0192\n",
      "Epoch 00857: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0205\n",
      "Epoch 858/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00858: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0160\n",
      "Epoch 859/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1053\n",
      "Epoch 00859: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.0779\n",
      "Epoch 860/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0232\n",
      "Epoch 00860: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0195\n",
      "Epoch 861/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1154\n",
      "Epoch 00861: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1637\n",
      "Epoch 862/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0448\n",
      "Epoch 00862: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0461\n",
      "Epoch 863/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0666\n",
      "Epoch 00863: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0534\n",
      "Epoch 864/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0074\n",
      "Epoch 00864: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0144\n",
      "Epoch 865/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0205\n",
      "Epoch 00865: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0230\n",
      "Epoch 866/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0329\n",
      "Epoch 00866: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0257\n",
      "Epoch 867/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.2516\n",
      "Epoch 00867: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.2049\n",
      "Epoch 868/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0242\n",
      "Epoch 00868: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1348\n",
      "Epoch 869/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1005\n",
      "Epoch 00869: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0871\n",
      "Epoch 870/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0355\n",
      "Epoch 00870: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0297\n",
      "Epoch 871/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0466\n",
      "Epoch 00871: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0393\n",
      "Epoch 872/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0771\n",
      "Epoch 00872: loss did not improve from 0.00651\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1406\n",
      "Epoch 873/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0057\n",
      "Epoch 00873: loss improved from 0.00651 to 0.00546, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0053\n",
      "Epoch 874/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0275     \n",
      "Epoch 00874: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0184\n",
      "Epoch 875/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0650\n",
      "Epoch 00875: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1126\n",
      "Epoch 876/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0084\n",
      "Epoch 00876: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0102\n",
      "Epoch 877/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0453\n",
      "Epoch 00877: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0430\n",
      "Epoch 878/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0123    \n",
      "Epoch 00878: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0114\n",
      "Epoch 879/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0526\n",
      "Epoch 00879: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0410\n",
      "Epoch 880/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0153\n",
      "Epoch 00880: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0120\n",
      "Epoch 881/1000\n",
      "11/18 [=================>............] - ETA: 0s - loss: 0.0409\n",
      "Epoch 00881: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0312\n",
      "Epoch 882/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0502\n",
      "Epoch 00882: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0391\n",
      "Epoch 883/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0104\n",
      "Epoch 00883: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0674\n",
      "Epoch 884/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0341\n",
      "Epoch 00884: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0406\n",
      "Epoch 885/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1404\n",
      "Epoch 00885: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.1269\n",
      "Epoch 886/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0044\n",
      "Epoch 00886: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 49ms/step - loss: 0.0114\n",
      "Epoch 887/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0246\n",
      "Epoch 00887: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0244\n",
      "Epoch 888/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0563\n",
      "Epoch 00888: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0571\n",
      "Epoch 889/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0323\n",
      "Epoch 00889: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0306\n",
      "Epoch 890/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0442\n",
      "Epoch 00890: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0952\n",
      "Epoch 891/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0798\n",
      "Epoch 00891: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0672\n",
      "Epoch 892/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0452\n",
      "Epoch 00892: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0435\n",
      "Epoch 893/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1705\n",
      "Epoch 00893: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1551\n",
      "Epoch 894/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0711\n",
      "Epoch 00894: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0673\n",
      "Epoch 895/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0689\n",
      "Epoch 00895: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0611\n",
      "Epoch 896/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1402\n",
      "Epoch 00896: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1860\n",
      "Epoch 897/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.1413    \n",
      "Epoch 00897: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1448\n",
      "Epoch 898/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0881\n",
      "Epoch 00898: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0834\n",
      "Epoch 899/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0461\n",
      "Epoch 00899: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0399\n",
      "Epoch 900/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0535\n",
      "Epoch 00900: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0543\n",
      "Epoch 901/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1433\n",
      "Epoch 00901: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1158\n",
      "Epoch 902/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0559\n",
      "Epoch 00902: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 0.0513\n",
      "Epoch 903/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0409\n",
      "Epoch 00903: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0387\n",
      "Epoch 904/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1206\n",
      "Epoch 00904: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1074\n",
      "Epoch 905/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0250\n",
      "Epoch 00905: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0424\n",
      "Epoch 906/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1031\n",
      "Epoch 00906: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1435\n",
      "Epoch 907/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0229    \n",
      "Epoch 00907: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0197\n",
      "Epoch 908/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1113\n",
      "Epoch 00908: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1137\n",
      "Epoch 909/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0280\n",
      "Epoch 00909: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0313\n",
      "Epoch 910/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0267\n",
      "Epoch 00910: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1128\n",
      "Epoch 911/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0462\n",
      "Epoch 00911: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1037\n",
      "Epoch 912/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0062\n",
      "Epoch 00912: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0079\n",
      "Epoch 913/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0335\n",
      "Epoch 00913: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1016\n",
      "Epoch 914/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0407\n",
      "Epoch 00914: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0386\n",
      "Epoch 915/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00915: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0101\n",
      "Epoch 916/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1337\n",
      "Epoch 00916: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1265\n",
      "Epoch 917/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0446\n",
      "Epoch 00917: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1241\n",
      "Epoch 918/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0507\n",
      "Epoch 00918: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0510\n",
      "Epoch 919/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0080    \n",
      "Epoch 00919: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0104\n",
      "Epoch 920/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0667\n",
      "Epoch 00920: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1229\n",
      "Epoch 921/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0585\n",
      "Epoch 00921: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0589\n",
      "Epoch 922/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1615\n",
      "Epoch 00922: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1488\n",
      "Epoch 923/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0634\n",
      "Epoch 00923: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0565\n",
      "Epoch 924/1000\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 0.0799\n",
      "Epoch 00924: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0618\n",
      "Epoch 925/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0796\n",
      "Epoch 00925: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.0753\n",
      "Epoch 926/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0729\n",
      "Epoch 00926: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0704\n",
      "Epoch 927/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0227\n",
      "Epoch 00927: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0963\n",
      "Epoch 928/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0274\n",
      "Epoch 00928: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0275\n",
      "Epoch 929/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1112\n",
      "Epoch 00929: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0993\n",
      "Epoch 930/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0566\n",
      "Epoch 00930: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0504\n",
      "Epoch 931/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00931: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0143\n",
      "Epoch 932/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0879\n",
      "Epoch 00932: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1292\n",
      "Epoch 933/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1181\n",
      "Epoch 00933: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1117\n",
      "Epoch 934/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1722\n",
      "Epoch 00934: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1719\n",
      "Epoch 935/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0181\n",
      "Epoch 00935: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0172\n",
      "Epoch 936/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0278\n",
      "Epoch 00936: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0945\n",
      "Epoch 937/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0163\n",
      "Epoch 00937: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0143\n",
      "Epoch 938/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0094\n",
      "Epoch 00938: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0084\n",
      "Epoch 939/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0106\n",
      "Epoch 00939: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0119\n",
      "Epoch 940/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0222\n",
      "Epoch 00940: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0174\n",
      "Epoch 941/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.1191\n",
      "Epoch 00941: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.1127\n",
      "Epoch 942/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0259\n",
      "Epoch 00942: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0413\n",
      "Epoch 943/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0133\n",
      "Epoch 00943: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0128\n",
      "Epoch 944/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0151\n",
      "Epoch 00944: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0139\n",
      "Epoch 945/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0119\n",
      "Epoch 00945: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0110\n",
      "Epoch 946/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0194\n",
      "Epoch 00946: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0445\n",
      "Epoch 947/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0103\n",
      "Epoch 00947: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0116\n",
      "Epoch 948/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0113\n",
      "Epoch 00948: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0134\n",
      "Epoch 949/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00949: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0109\n",
      "Epoch 950/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0331\n",
      "Epoch 00950: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1413\n",
      "Epoch 951/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0788\n",
      "Epoch 00951: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0637\n",
      "Epoch 952/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1123\n",
      "Epoch 00952: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1523\n",
      "Epoch 953/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0227\n",
      "Epoch 00953: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0185\n",
      "Epoch 954/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0540\n",
      "Epoch 00954: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0481\n",
      "Epoch 955/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0508\n",
      "Epoch 00955: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1045\n",
      "Epoch 956/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0315\n",
      "Epoch 00956: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0351\n",
      "Epoch 957/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1011\n",
      "Epoch 00957: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1425\n",
      "Epoch 958/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1091\n",
      "Epoch 00958: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.1156\n",
      "Epoch 959/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0864\n",
      "Epoch 00959: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0753\n",
      "Epoch 960/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0367\n",
      "Epoch 00960: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0585\n",
      "Epoch 961/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0430\n",
      "Epoch 00961: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0407\n",
      "Epoch 962/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0447\n",
      "Epoch 00962: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0393\n",
      "Epoch 963/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0301\n",
      "Epoch 00963: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0502\n",
      "Epoch 964/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1690\n",
      "Epoch 00964: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 47ms/step - loss: 0.1226\n",
      "Epoch 965/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.1175\n",
      "Epoch 00965: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0918\n",
      "Epoch 966/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0119\n",
      "Epoch 00966: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0171\n",
      "Epoch 967/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0546\n",
      "Epoch 00967: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0516\n",
      "Epoch 968/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1075\n",
      "Epoch 00968: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0959\n",
      "Epoch 969/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0316\n",
      "Epoch 00969: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 48ms/step - loss: 0.0903\n",
      "Epoch 970/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0214\n",
      "Epoch 00970: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0191\n",
      "Epoch 971/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0462\n",
      "Epoch 00971: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1082\n",
      "Epoch 972/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.2138 \n",
      "Epoch 00972: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.1173\n",
      "Epoch 973/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1112\n",
      "Epoch 00973: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1162\n",
      "Epoch 974/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0201\n",
      "Epoch 00974: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 0.0191\n",
      "Epoch 975/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0494\n",
      "Epoch 00975: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0413\n",
      "Epoch 976/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0019    \n",
      "Epoch 00976: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0198\n",
      "Epoch 977/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0364\n",
      "Epoch 00977: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0344\n",
      "Epoch 978/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0141\n",
      "Epoch 00978: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0222\n",
      "Epoch 979/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.1933\n",
      "Epoch 00979: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.1752\n",
      "Epoch 980/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0605\n",
      "Epoch 00980: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0687\n",
      "Epoch 981/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0395\n",
      "Epoch 00981: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.1046\n",
      "Epoch 982/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0639\n",
      "Epoch 00982: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0655\n",
      "Epoch 983/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0102\n",
      "Epoch 00983: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0697\n",
      "Epoch 984/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0067\n",
      "Epoch 00984: loss did not improve from 0.00546\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 0.0069\n",
      "Epoch 985/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0052\n",
      "Epoch 00985: loss improved from 0.00546 to 0.00498, saving model to /content/gdrive/My Drive/tinkoffCV/encoder/model_x64_x32_x16_256.h5\n",
      "18/18 [==============================] - 1s 59ms/step - loss: 0.0048\n",
      "Epoch 986/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0089\n",
      "Epoch 00986: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 0.0084\n",
      "Epoch 987/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0094 \n",
      "Epoch 00987: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0094\n",
      "Epoch 988/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0064\n",
      "Epoch 00988: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0054\n",
      "Epoch 989/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0048\n",
      "Epoch 00989: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0114\n",
      "Epoch 990/1000\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 0.0355\n",
      "Epoch 00990: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0277\n",
      "Epoch 991/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0122\n",
      "Epoch 00991: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0115\n",
      "Epoch 992/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0165\n",
      "Epoch 00992: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.0772\n",
      "Epoch 993/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0077    \n",
      "Epoch 00993: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 43ms/step - loss: 0.0065\n",
      "Epoch 994/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0781\n",
      "Epoch 00994: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0865\n",
      "Epoch 995/1000\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 0.0429\n",
      "Epoch 00995: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0522\n",
      "Epoch 996/1000\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 0.0931 \n",
      "Epoch 00996: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0744\n",
      "Epoch 997/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.1295\n",
      "Epoch 00997: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.1194\n",
      "Epoch 998/1000\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 0.0641\n",
      "Epoch 00998: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0537\n",
      "Epoch 999/1000\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 0.0250\n",
      "Epoch 00999: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.0211\n",
      "Epoch 1000/1000\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0786\n",
      "Epoch 01000: loss did not improve from 0.00498\n",
      "18/18 [==============================] - 1s 39ms/step - loss: 0.0753\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=1000,\n",
    "                    callbacks=[tf.keras.callbacks.TensorBoard(os.path.join(work_path, \"encoder/log\")),\n",
    "                               tf.keras.callbacks.ModelCheckpoint(os.path.join(work_path, \"encoder/model_x64_x32_x16_256.h5\"),\n",
    "                                                                  monitor=\"loss\", verbose=1, save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "36bYrzsRgRxS",
    "outputId": "3a1d0774-03fc-4d97-ae1c-559a8388f9a8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgs6wzBMlPD/Oshrm/GKK+AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "\n",
    "plt.plot(range(1000), loss, label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b2ML8Td89MDM"
   },
   "source": [
    "# Encoding images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdthchWcN7CB"
   },
   "outputs": [],
   "source": [
    "encoder = tf.keras.models.load_model(os.path.join(work_path, \"encoder/model_x64_x32_x16_256.h5\"), compile=False)\n",
    "\n",
    "encoder.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "                   loss=tfa.losses.TripletSemiHardLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dky1iuxJKrck"
   },
   "outputs": [],
   "source": [
    "ds = create_dataset(paths, labels, trainable=False)\n",
    "\n",
    "labels = []\n",
    "for x, y in ds:\n",
    "    labels += list(y.numpy())\n",
    "\n",
    "embeddings = encoder.predict(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_8l_EaGVAXO"
   },
   "outputs": [],
   "source": [
    "np.save(os.path.join(work_path, \"encoder/embeddings.npy\"), embeddings)\n",
    "np.save(os.path.join(work_path, \"encoder/labels.npy\"), np.array(labels, dtype=np.uint8))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tinkoff CV.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
